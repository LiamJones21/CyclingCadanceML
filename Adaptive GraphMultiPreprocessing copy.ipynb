{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -U scikit-learn pandas numpy joblib scipy optuna matplotlib ipywidgets xgboost lightgbm pywavelets seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages (if not already installed)\n",
    "# Uncomment and run the following lines if necessary:\n",
    "# %pip install -q -U scikit-learn pandas numpy joblib scipy optuna matplotlib ipywidgets xgboost lightgbm pywavelets seaborn\n",
    "\n",
    "# Imports\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from scipy.fft import fft\n",
    "from scipy.signal import butter, filtfilt\n",
    "import pywt  # For wavelet transforms\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, accuracy_score, confusion_matrix\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ipywidgets import IntSlider, ToggleButtons, Dropdown, interactive_output, HBox, VBox, Output\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Load and Correct the Data\n",
    "\n",
    "# Load the data\n",
    "with open('cycling_data2.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Define gear ratios and wheel circumference\n",
    "gear_ratios = {\n",
    "    1: 38.0 / 11.0,\n",
    "    2: 38.0 / 15.0,\n",
    "    3: 38.0 / 18.0,\n",
    "    4: 38.0 / 21.0,\n",
    "    5: 38.0 / 24.0,\n",
    "    6: 38.0 / 34.0,\n",
    "    # Add all your gear ratios\n",
    "}\n",
    "wheel_circumference = 2.19999  # in meters\n",
    "\n",
    "# Flatten the data and recalculate cadence\n",
    "records = []\n",
    "for session in data:\n",
    "    for point in session['data']:\n",
    "        gear = point['gear']\n",
    "        speed = point['speed']  # in m/s\n",
    "        gear_ratio = gear_ratios.get(gear, None)\n",
    "        if gear_ratio and speed > 0:\n",
    "            cadence = (speed / wheel_circumference) * gear_ratio * 60\n",
    "        else:\n",
    "            cadence = 0.0\n",
    "        point['cadence'] = cadence\n",
    "        records.append({\n",
    "            'timestamp': point['timestamp'],\n",
    "            'accel_x': point['accelerometerData']['x'],\n",
    "            'accel_y': point['accelerometerData']['y'],\n",
    "            'accel_z': point['accelerometerData']['z'],\n",
    "            'speed': speed,\n",
    "            'cadence': cadence,\n",
    "            'gear': gear,\n",
    "            'terrain': point['terrain'],\n",
    "            'is_standing': point['isStanding']\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame and Ensure Temporal Order\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df.sort_values('timestamp', inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: Define Functions for Feature Extraction and Signal Processing\n",
    "\n",
    "def bandpass_filter(data, lowcut, highcut, fs, order=4):\n",
    "    nyq = 0.5 * fs  # Nyquist Frequency\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    y = filtfilt(b, a, data)\n",
    "    return y\n",
    "\n",
    "def extract_features(window, include_fft=True, apply_filter=False, include_wavelet=False):\n",
    "    # Extract accelerometer data\n",
    "    accel_x = window['accel_x'].values\n",
    "    accel_y = window['accel_y'].values\n",
    "    accel_z = window['accel_z'].values\n",
    "\n",
    "    if apply_filter:\n",
    "        # Apply band-pass filter\n",
    "        fs = 50  # Sampling frequency\n",
    "        lowcut = 0.5\n",
    "        highcut = 3.0  # Adjust based on expected cadence frequency range\n",
    "        accel_x = bandpass_filter(accel_x, lowcut, highcut, fs)\n",
    "        accel_y = bandpass_filter(accel_y, lowcut, highcut, fs)\n",
    "        accel_z = bandpass_filter(accel_z, lowcut, highcut, fs)\n",
    "\n",
    "    features = []\n",
    "\n",
    "    # Time-domain features\n",
    "    for accel in [accel_x, accel_y, accel_z]:\n",
    "        features.extend([\n",
    "            np.mean(accel),\n",
    "            np.std(accel),\n",
    "            np.var(accel),\n",
    "            np.min(accel),\n",
    "            np.max(accel),\n",
    "            np.median(accel),\n",
    "            np.percentile(accel, 25),\n",
    "            np.percentile(accel, 75),\n",
    "        ])\n",
    "\n",
    "    # Frequency-domain features\n",
    "    if include_fft:\n",
    "        for accel in [accel_x, accel_y, accel_z]:\n",
    "            fft_values = fft(accel)\n",
    "            fft_magnitude = np.abs(fft_values)[:len(fft_values)//2]\n",
    "            features.extend([\n",
    "                np.mean(fft_magnitude),\n",
    "                np.std(fft_magnitude),\n",
    "                np.max(fft_magnitude),\n",
    "                np.argmax(fft_magnitude),  # Dominant frequency component\n",
    "            ])\n",
    "\n",
    "    # Wavelet features\n",
    "    if include_wavelet:\n",
    "        for accel in [accel_x, accel_y, accel_z]:\n",
    "            coeffs = pywt.wavedec(accel, 'db1', level=3)\n",
    "            # Use approximation coefficients at the third level\n",
    "            cA3 = coeffs[0]\n",
    "            features.extend([\n",
    "                np.mean(cA3),\n",
    "                np.std(cA3),\n",
    "            ])\n",
    "\n",
    "    # Add speed feature\n",
    "    features.append(window['speed'].mean())\n",
    "\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 3: Define the Interactive Visualization Function with Dynamic Model Training\n",
    "\n",
    "# Function to calculate gear from cadence and speed\n",
    "def calculate_gear(cadence, speed, wheel_circumference, gear_ratios):\n",
    "    if speed == 0:\n",
    "        return np.nan\n",
    "    # Calculate gear ratio\n",
    "    gear_ratio_calculated = (cadence * wheel_circumference) / (speed * 60)\n",
    "    # Match to the closest gear ratio\n",
    "    gear_ratio_values = np.array(list(gear_ratios.values()))\n",
    "    gear_numbers = np.array(list(gear_ratios.keys()))\n",
    "    idx = (np.abs(gear_ratio_values - gear_ratio_calculated)).argmin()\n",
    "    predicted_gear = gear_numbers[idx]\n",
    "    return predicted_gear\n",
    "\n",
    "# Cache models to avoid retraining if parameters are the same\n",
    "model_cache = {}\n",
    "\n",
    "def interactive_plot(window_size, window_step, include_fft, include_wavelet, scaler_name, apply_filter, use_pca, model_type, window_index):\n",
    "    params_key = (window_size, window_step, include_fft, include_wavelet, scaler_name, apply_filter, use_pca, model_type)\n",
    "    start_time = time.time()\n",
    "    if params_key in model_cache:\n",
    "        data = model_cache[params_key]\n",
    "    else:\n",
    "        # Prepare data\n",
    "        X = []\n",
    "        y_cadence = []\n",
    "        y_gear = []\n",
    "        X_raw = []\n",
    "\n",
    "        # Generate windows\n",
    "        for start_idx in range(0, len(df) - window_size, window_step):\n",
    "            end_idx = start_idx + window_size\n",
    "            window = df.iloc[start_idx:end_idx]\n",
    "\n",
    "            # Extract features\n",
    "            features = extract_features(window, include_fft=include_fft, apply_filter=apply_filter, include_wavelet=include_wavelet)\n",
    "            X.append(features)\n",
    "            y_cadence.append(window['cadence'].mean())\n",
    "            y_gear.append(window['gear'].mode()[0])\n",
    "\n",
    "            # Store raw data for visualization\n",
    "            X_raw.append({\n",
    "                'accel_x': window['accel_x'].values,\n",
    "                'accel_y': window['accel_y'].values,\n",
    "                'accel_z': window['accel_z'].values,\n",
    "                'speed': window['speed'].mean(),\n",
    "            })\n",
    "\n",
    "        X = np.array(X)\n",
    "        y_cadence = np.array(y_cadence)\n",
    "        y_gear = np.array(y_gear)\n",
    "\n",
    "        # Handle missing values\n",
    "        imputer = SimpleImputer(strategy='mean')\n",
    "        X = imputer.fit_transform(X)\n",
    "\n",
    "        # Select scaler\n",
    "        if scaler_name == 'StandardScaler':\n",
    "            scaler = StandardScaler()\n",
    "        elif scaler_name == 'MinMaxScaler':\n",
    "            scaler = MinMaxScaler()\n",
    "        else:\n",
    "            scaler = RobustScaler()\n",
    "\n",
    "        # Scale features\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "        # Apply PCA if selected\n",
    "        if use_pca:\n",
    "            pca = PCA(n_components=0.95)\n",
    "            X_scaled = pca.fit_transform(X_scaled)\n",
    "\n",
    "        # Time-based splitting\n",
    "        split_index = int(0.8 * len(X_scaled))\n",
    "        X_train, X_test = X_scaled[:split_index], X_scaled[split_index:]\n",
    "        y_train_cadence, y_test_cadence = y_cadence[:split_index], y_cadence[split_index:]\n",
    "        y_test_gear = y_gear[split_index:]\n",
    "        X_test_raw = X_raw[split_index:]\n",
    "\n",
    "        # Select and train model\n",
    "        if model_type == 'RandomForest':\n",
    "            model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "        elif model_type == 'LightGBM':\n",
    "            model = lgb.LGBMRegressor(n_estimators=100, random_state=42)\n",
    "        else:\n",
    "            model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "        # Training the model\n",
    "        with output:\n",
    "            output.clear_output(wait=True)\n",
    "            print(\"Training model, please wait...\")\n",
    "        model.fit(X_train, y_train_cadence)\n",
    "\n",
    "        # Store the model and data in cache\n",
    "        data = {\n",
    "            'model': model,\n",
    "            'scaler': scaler,\n",
    "            'X_test': X_test,\n",
    "            'y_test_cadence': y_test_cadence,\n",
    "            'y_test_gear': y_test_gear,\n",
    "            'X_test_raw': X_test_raw,\n",
    "        }\n",
    "        model_cache[params_key] = data\n",
    "\n",
    "    # Retrieve data\n",
    "    model = data['model']\n",
    "    X_test = data['X_test']\n",
    "    y_test_cadence = data['y_test_cadence']\n",
    "    y_test_gear = data['y_test_gear']\n",
    "    X_test_raw = data['X_test_raw']\n",
    "\n",
    "    idx = window_index  # Each index corresponds to one window\n",
    "\n",
    "    # Get the test sample\n",
    "    X_sample = X_test[idx].reshape(1, -1)\n",
    "    y_actual_cadence = y_test_cadence[idx]\n",
    "    y_actual_gear = y_test_gear[idx]\n",
    "    X_raw_sample = X_test_raw[idx]\n",
    "\n",
    "    # Predict using the model\n",
    "    y_pred_cadence = model.predict(X_sample)[0]\n",
    "\n",
    "    # Calculate predicted gear\n",
    "    speed = X_raw_sample['speed']\n",
    "    predicted_gear = calculate_gear(y_pred_cadence, speed, wheel_circumference, gear_ratios)\n",
    "\n",
    "    # Plot accelerometer data\n",
    "    fig, axs = plt.subplots(4, 1, figsize=(12, 16))\n",
    "\n",
    "    accel_x = X_raw_sample['accel_x']\n",
    "    accel_y = X_raw_sample['accel_y']\n",
    "    accel_z = X_raw_sample['accel_z']\n",
    "    time_accel = np.arange(len(accel_x)) / 50  # Assuming 50 Hz sampling rate\n",
    "\n",
    "    axs[0].plot(time_accel, accel_x, label='Accel X')\n",
    "    axs[0].plot(time_accel, accel_y, label='Accel Y')\n",
    "    axs[0].plot(time_accel, accel_z, label='Accel Z')\n",
    "    axs[0].set_title('Accelerometer Data')\n",
    "    axs[0].set_xlabel('Time (s)')\n",
    "    axs[0].set_ylabel('Acceleration')\n",
    "    \n",
    "    axs[0].legend()\n",
    "\n",
    "    # Plot actual vs predicted cadence\n",
    "    axs[1].bar(['Actual Cadence', 'Predicted Cadence'], [y_actual_cadence, y_pred_cadence], color=['blue', 'orange'])\n",
    "    axs[1].set_title('Actual vs. Predicted Cadence')\n",
    "    axs[1].set_ylabel('Cadence (RPM)')\n",
    "# set the y axis to be the max of the actual and predicted cadence\n",
    "    axs[1].set_ylim([0, max(y_actual_cadence, y_pred_cadence) + 10])\n",
    "\n",
    "    # Plot actual gear vs predicted gear\n",
    "    axs[2].bar(['Actual Gear', 'Predicted Gear'], [y_actual_gear, predicted_gear], color=['green', 'red'])\n",
    "    axs[2].set_title('Actual vs. Predicted Gear')\n",
    "    axs[2].set_ylabel('Gear Number')\n",
    "    axs[2].set_ylim([0, 7])\n",
    "\n",
    "    # Plot speed\n",
    "    axs[3].bar(['Speed'], [speed], color='purple')\n",
    "    axs[3].set_title('Speed')\n",
    "    axs[3].set_ylabel('Speed (m/s)')\n",
    "    axs[3].set_ylim([0.0, speed + 1.0])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    with output:\n",
    "        output.clear_output(wait=True)\n",
    "        print(f\"Model trained in {time.time() - start_time:.2f} seconds.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6de557850c04236a366bbba04d12ffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Window Size:', index=4, options=(10, 30, 50, 100, 200, 300â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3748aa146214965907c2ef56a69d863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Step 4: Create Interactive Widgets\n",
    "\n",
    "# Widgets for parameters\n",
    "window_sizes = [10,30,50,100, 200, 300,500]\n",
    "window_steps = [5,20,50, 100]\n",
    "include_fft_options = [('Yes', True), ('No', False)]\n",
    "include_wavelet_options = [('Yes', True), ('No', False)]\n",
    "scaler_options = ['StandardScaler', 'MinMaxScaler']\n",
    "filter_options = [('Yes', True), ('No', False)]\n",
    "pca_options = [('Yes', True), ('No', False)]\n",
    "model_types = ['RandomForest', 'LightGBM']\n",
    "\n",
    "window_size_slider = Dropdown(\n",
    "    options=window_sizes,\n",
    "    value=200,\n",
    "    description='Window Size:',\n",
    ")\n",
    "\n",
    "window_step_slider = Dropdown(\n",
    "    options=window_steps,\n",
    "    value=50,\n",
    "    description='Overlap:',\n",
    ")\n",
    "\n",
    "include_fft_toggle = ToggleButtons(\n",
    "    options=include_fft_options,\n",
    "    value=True,\n",
    "    description='Include FFT:',\n",
    ")\n",
    "\n",
    "include_wavelet_toggle = ToggleButtons(\n",
    "    options=include_wavelet_options,\n",
    "    value=False,\n",
    "    description='Include Wavelet:',\n",
    ")\n",
    "\n",
    "scaler_dropdown = Dropdown(\n",
    "    options=scaler_options,\n",
    "    value='StandardScaler',\n",
    "    description='Scaler:',\n",
    ")\n",
    "\n",
    "filter_toggle = ToggleButtons(\n",
    "    options=filter_options,\n",
    "    value=False,\n",
    "    description='Apply Filter:',\n",
    ")\n",
    "\n",
    "pca_toggle = ToggleButtons(\n",
    "    options=pca_options,\n",
    "    value=False,\n",
    "    description='Use PCA:',\n",
    ")\n",
    "\n",
    "model_type_dropdown = Dropdown(\n",
    "    options=model_types,\n",
    "    value='RandomForest',\n",
    "    description='Model Type:',\n",
    ")\n",
    "\n",
    "# Function to update the window index slider based on selected parameters\n",
    "def update_window_index(*args):\n",
    "    # Since the data length depends on window_size and window_step, we need to calculate it\n",
    "    window_size = window_size_slider.value\n",
    "    window_step = window_step_slider.value\n",
    "    num_windows = (len(df) - window_size) // window_step\n",
    "    window_index_slider.max = max(num_windows - 1, 0)\n",
    "\n",
    "# Window index slider\n",
    "window_index_slider = IntSlider(min=0, max=10, step=1, description='Window Index')\n",
    "\n",
    "# Observe changes to update window index slider max value\n",
    "window_size_slider.observe(update_window_index, 'value')\n",
    "window_step_slider.observe(update_window_index, 'value')\n",
    "\n",
    "# Initialize window index slider max value\n",
    "update_window_index()\n",
    "\n",
    "# Output widget to display training messages\n",
    "output = Output()\n",
    "\n",
    "# Interactive output\n",
    "ui = VBox([\n",
    "    HBox([window_size_slider, window_step_slider]),\n",
    "    HBox([include_fft_toggle, include_wavelet_toggle]),\n",
    "    HBox([scaler_dropdown, filter_toggle]),\n",
    "    HBox([pca_toggle, model_type_dropdown]),\n",
    "    window_index_slider,\n",
    "    output\n",
    "])\n",
    "\n",
    "out = interactive_output(\n",
    "    interactive_plot,\n",
    "    {\n",
    "        'window_size': window_size_slider,\n",
    "        'window_step': window_step_slider,\n",
    "        'include_fft': include_fft_toggle,\n",
    "        'include_wavelet': include_wavelet_toggle,\n",
    "        'scaler_name': scaler_dropdown,\n",
    "        'apply_filter': filter_toggle,\n",
    "        'use_pca': pca_toggle,\n",
    "        'model_type': model_type_dropdown,\n",
    "        'window_index': window_index_slider\n",
    "    }\n",
    ")\n",
    "\n",
    "display(ui, out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
